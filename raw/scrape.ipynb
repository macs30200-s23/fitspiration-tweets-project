{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample time\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "# scraping\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "# data collection\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to Kim et al. (2018), it is necessary to include around 38% of Twitter content in order to represent the entire period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_weeks(start_date, end_date):\n",
    "    '''\n",
    "    Sample about 38% of the weeks of start date to end date\n",
    "    Input:\n",
    "        Two dates in datetime.date format\n",
    "    Output:\n",
    "        A list of sampled dates that are ending cutoff points of the sampled weeks\n",
    "    '''\n",
    "\n",
    "    delta = datetime.timedelta(days=7) # 7-day time period\n",
    "\n",
    "    current_date = start_date\n",
    "\n",
    "    weeks = []\n",
    "\n",
    "    while current_date <= end_date:\n",
    "        period_start = current_date\n",
    "        period_end = current_date + delta - datetime.timedelta(days=1)\n",
    "        # the last end date can't exceed the sampling period\n",
    "        if period_end > end_date:\n",
    "            period_end = end_date\n",
    "        weeks.append((period_start, period_end))\n",
    "        current_date += delta\n",
    "\n",
    "    sample_size = int(len(weeks) * 0.38)\n",
    "    sampled_weeks = random.sample(weeks, sample_size)\n",
    "    \n",
    "    return sampled_weeks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entire study period was categorized into the following three time periods: \n",
    "- pre-pandemic (March 1, 2019 - December 31, 2019)\n",
    "- early-pandemic (March 1, 2020 - December 31, 2020)\n",
    "- late-pandemic (March 1, 2022 - December 31, 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the start/end dates of the three periods\n",
    "# pre-pandemic period\n",
    "p1_start = datetime.date(2019, 3, 1)\n",
    "p1_end = datetime.date(2019, 12, 31)\n",
    "\n",
    "# early-pandemic\n",
    "p2_start = datetime.date(2020, 3, 1)\n",
    "p2_end = datetime.date(2020, 12, 31)\n",
    "\n",
    "# late-pandemic\n",
    "p3_start = datetime.date(2022, 3, 1)\n",
    "p3_end = datetime.date(2022, 12, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sample the weeks for each period based on the pre-defined start and end date\n",
    "p1_sample = sample_weeks(p1_start, p1_end)\n",
    "p2_sample = sample_weeks(p2_start, p2_end)\n",
    "p3_sample = sample_weeks(p3_start, p3_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each period has 16 weeks sampled\n",
    "len(p1_sample) == len(p2_sample) == len(p3_sample) == 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hashtag and timeframe\n",
    "hashtag = \"fitspo\"\n",
    "language = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If not already installed\n",
    "#! pip install snscrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_tweets(sampled_weeks, period_id):\n",
    "    '''\n",
    "    Input:\n",
    "        sampled_weeks: a list of tuples that contain the start and end date of the week\n",
    "                        e.g.: (datetime.date(2019, 3, 22), datetime.date(2019, 3, 28))\n",
    "        period_id: \n",
    "            0: pre-pandemic, 1: early-pandemic, 2: late-pandemic\n",
    "    '''\n",
    "    \n",
    "    # store all rows\n",
    "    csv_rows = []\n",
    "\n",
    "    for week in sampled_weeks:\n",
    "        start_date = str(week[0])\n",
    "        end_date = str(week[1])\n",
    "\n",
    "        # Define the snscrape command, excluding retweets\n",
    "        command = f'snscrape --jsonl twitter-hashtag \"{hashtag} lang:{language} since:{start_date} until:{end_date} -filter:retweets\"'\n",
    "\n",
    "        # Run the snscrape command and capture the output\n",
    "        output = subprocess.check_output(command, shell=True)\n",
    "\n",
    "        # Decode the JSON output\n",
    "        tweets = [json.loads(line) for line in output.splitlines()]\n",
    "\n",
    "        rows = [[period_id, t['username'], t['date'], t['url'], t['rawContent'], \n",
    "                t['id'], t['mentionedUsers'], \n",
    "                t['coordinates']['longitude'] if t.get('coordinates') else None,\n",
    "                t['coordinates']['latitude'] if t.get('coordinates') else None,\n",
    "                t['place']['countryCode'] if t.get('place') else None,\n",
    "                t['place']['fullName'] if t.get('place') else None,\n",
    "                t['user']['id'], t['user']['followersCount'], \n",
    "                t['user']['description'], t['user']['url']]\n",
    "                for t in tweets]\n",
    "        \n",
    "        csv_rows.extend(rows)\n",
    "        time.sleep(10)\n",
    "    print('Finished scraping for one period!')\n",
    "\n",
    "    return csv_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jiayan/Downloads/codes_macs_2022-2023/macs30200/replication-materials-jiayanli/data\n"
     ]
    }
   ],
   "source": [
    "# Header for the CSV file\n",
    "header = ['Period', 'Username', 'Date', 'URL', 'Content', 'TweetID', 'MentionedUsers', 'Longitude', 'Latitude',\n",
    "          'CountryCode', 'Place', 'UserID', 'FollowersCount', 'UserDescription', 'UserURL']\n",
    "\n",
    "# Get the current working directory path\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Print the updated directory path\n",
    "dir_path = cwd.rstrip(\"/raw\") + \"/data\"\n",
    "print(dir_path)\n",
    "\n",
    "# Write the header to the file\n",
    "with open(dir_path + \"/raw_data.csv\", 'w', newline='') as f:\n",
    "    csvwriter = csv.writer(f)\n",
    "    csvwriter.writerow(header)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished scraping for one period!\n",
      "Finished adding data of period 0 to csv file\n",
      "Finished scraping for one period!\n",
      "Finished adding data of period 1 to csv file\n",
      "Finished scraping for one period!\n",
      "Finished adding data of period 2 to csv file\n"
     ]
    }
   ],
   "source": [
    "# Loop over samples of three periods\n",
    "for i, sample in enumerate([p1_sample, p2_sample, p3_sample]):\n",
    "    csv_rows = scrape_tweets(sample, i)\n",
    "\n",
    "    # Append data to the file\n",
    "    with open(dir_path + \"/raw_data.csv\", 'a', newline='') as f:\n",
    "        csvwriter = csv.writer(f)\n",
    "        csvwriter.writerows(csv_rows)\n",
    "\n",
    "    print(f'Finished adding data of period {i} to csv file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Period</th>\n",
       "      <th>Username</th>\n",
       "      <th>Date</th>\n",
       "      <th>URL</th>\n",
       "      <th>Content</th>\n",
       "      <th>TweetID</th>\n",
       "      <th>MentionedUsers</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>CountryCode</th>\n",
       "      <th>Place</th>\n",
       "      <th>UserID</th>\n",
       "      <th>FollowersCount</th>\n",
       "      <th>UserDescription</th>\n",
       "      <th>UserURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27129</th>\n",
       "      <td>2</td>\n",
       "      <td>CollinsGato</td>\n",
       "      <td>2022-06-28T03:33:13+00:00</td>\n",
       "      <td>https://twitter.com/CollinsGato/status/1541625...</td>\n",
       "      <td>#backinthehabit #8weekstogo #gym #fitspo #fitn...</td>\n",
       "      <td>1541625739916836864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2482589021</td>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/CollinsGato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27130</th>\n",
       "      <td>2</td>\n",
       "      <td>GetFitNLean</td>\n",
       "      <td>2022-06-28T03:00:11+00:00</td>\n",
       "      <td>https://twitter.com/GetFitNLean/status/1541617...</td>\n",
       "      <td>Work It #FitFam! Be More! Do MORE! #Fitness #m...</td>\n",
       "      <td>1541617429356453888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>705040642179727361</td>\n",
       "      <td>7811</td>\n",
       "      <td>Motivation #Fitness #Fitfam #FitSpo pictures a...</td>\n",
       "      <td>https://twitter.com/GetFitNLean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27131</th>\n",
       "      <td>2</td>\n",
       "      <td>Obi_Obadike</td>\n",
       "      <td>2022-06-28T02:31:33+00:00</td>\n",
       "      <td>https://twitter.com/Obi_Obadike/status/1541610...</td>\n",
       "      <td>The mind controls the body.\\n •\\n#motivation #...</td>\n",
       "      <td>1541610222078140416</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37002399</td>\n",
       "      <td>543571</td>\n",
       "      <td>Best Selling Co-Author of TheCut; Named Top 10...</td>\n",
       "      <td>https://twitter.com/Obi_Obadike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27132</th>\n",
       "      <td>2</td>\n",
       "      <td>GetFitNLean</td>\n",
       "      <td>2022-06-28T02:20:10+00:00</td>\n",
       "      <td>https://twitter.com/GetFitNLean/status/1541607...</td>\n",
       "      <td>#Fitspo Strong is the NEW Skinny! #GetFITnLEAN...</td>\n",
       "      <td>1541607357733642240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>705040642179727361</td>\n",
       "      <td>7811</td>\n",
       "      <td>Motivation #Fitness #Fitfam #FitSpo pictures a...</td>\n",
       "      <td>https://twitter.com/GetFitNLean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27133</th>\n",
       "      <td>2</td>\n",
       "      <td>GetFitNLean</td>\n",
       "      <td>2022-06-28T00:40:10+00:00</td>\n",
       "      <td>https://twitter.com/GetFitNLean/status/1541582...</td>\n",
       "      <td>#FitSpo Deadlifts for great hamstrings and glu...</td>\n",
       "      <td>1541582191016157185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>705040642179727361</td>\n",
       "      <td>7811</td>\n",
       "      <td>Motivation #Fitness #Fitfam #FitSpo pictures a...</td>\n",
       "      <td>https://twitter.com/GetFitNLean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Period     Username                       Date  \\\n",
       "27129       2  CollinsGato  2022-06-28T03:33:13+00:00   \n",
       "27130       2  GetFitNLean  2022-06-28T03:00:11+00:00   \n",
       "27131       2  Obi_Obadike  2022-06-28T02:31:33+00:00   \n",
       "27132       2  GetFitNLean  2022-06-28T02:20:10+00:00   \n",
       "27133       2  GetFitNLean  2022-06-28T00:40:10+00:00   \n",
       "\n",
       "                                                     URL  \\\n",
       "27129  https://twitter.com/CollinsGato/status/1541625...   \n",
       "27130  https://twitter.com/GetFitNLean/status/1541617...   \n",
       "27131  https://twitter.com/Obi_Obadike/status/1541610...   \n",
       "27132  https://twitter.com/GetFitNLean/status/1541607...   \n",
       "27133  https://twitter.com/GetFitNLean/status/1541582...   \n",
       "\n",
       "                                                 Content              TweetID  \\\n",
       "27129  #backinthehabit #8weekstogo #gym #fitspo #fitn...  1541625739916836864   \n",
       "27130  Work It #FitFam! Be More! Do MORE! #Fitness #m...  1541617429356453888   \n",
       "27131  The mind controls the body.\\n •\\n#motivation #...  1541610222078140416   \n",
       "27132  #Fitspo Strong is the NEW Skinny! #GetFITnLEAN...  1541607357733642240   \n",
       "27133  #FitSpo Deadlifts for great hamstrings and glu...  1541582191016157185   \n",
       "\n",
       "      MentionedUsers  Longitude  Latitude CountryCode Place  \\\n",
       "27129            NaN        NaN       NaN         NaN   NaN   \n",
       "27130            NaN        NaN       NaN         NaN   NaN   \n",
       "27131            NaN        NaN       NaN         NaN   NaN   \n",
       "27132            NaN        NaN       NaN         NaN   NaN   \n",
       "27133            NaN        NaN       NaN         NaN   NaN   \n",
       "\n",
       "                   UserID  FollowersCount  \\\n",
       "27129          2482589021              70   \n",
       "27130  705040642179727361            7811   \n",
       "27131            37002399          543571   \n",
       "27132  705040642179727361            7811   \n",
       "27133  705040642179727361            7811   \n",
       "\n",
       "                                         UserDescription  \\\n",
       "27129                                                NaN   \n",
       "27130  Motivation #Fitness #Fitfam #FitSpo pictures a...   \n",
       "27131  Best Selling Co-Author of TheCut; Named Top 10...   \n",
       "27132  Motivation #Fitness #Fitfam #FitSpo pictures a...   \n",
       "27133  Motivation #Fitness #Fitfam #FitSpo pictures a...   \n",
       "\n",
       "                               UserURL  \n",
       "27129  https://twitter.com/CollinsGato  \n",
       "27130  https://twitter.com/GetFitNLean  \n",
       "27131  https://twitter.com/Obi_Obadike  \n",
       "27132  https://twitter.com/GetFitNLean  \n",
       "27133  https://twitter.com/GetFitNLean  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv file\n",
    "df = pd.read_csv(dir_path + \"/raw_data.csv\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27134, 15)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show data size\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Period                 0\n",
       "Username               0\n",
       "Date                   0\n",
       "URL                    0\n",
       "Content                0\n",
       "TweetID                0\n",
       "MentionedUsers     24300\n",
       "Longitude          23750\n",
       "Latitude           23750\n",
       "CountryCode        23752\n",
       "Place              23752\n",
       "UserID                 0\n",
       "FollowersCount         0\n",
       "UserDescription     2048\n",
       "UserURL                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check null values for each variable\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-pandemic period sample size: 15287\n",
      "Early-pandemic period sample size: 8597\n",
      "Late-pandemic period sample size: 3250\n"
     ]
    }
   ],
   "source": [
    "print(f\"Pre-pandemic period sample size: {df[df['Period'] == 0].shape[0]}\")\n",
    "print(f\"Early-pandemic period sample size: {df[df['Period'] == 1].shape[0]}\")\n",
    "print(f\"Late-pandemic period sample size: {df[df['Period'] == 2].shape[0]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16 weeks were randomly sampled from each of the pre-, early-, and late-pandemic periods. A total of 27134 tweets posted within the sampled weeks with the hashtag \"#fitspo\" were collected. \n",
    "\n",
    "From the above, we can conclude that:\n",
    "\n",
    "- The majority of tweets do not have information on the posting location (including longitude, latitude, country, and place) and do not mention any other users.\n",
    "- A few tweets are posted by users who do not have a user description.\n",
    "- The sample size volume: Pre-pandemic > Early-pandemic > Late-pandemic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
