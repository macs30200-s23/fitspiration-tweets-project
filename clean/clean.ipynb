{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jiayan/Downloads/codes_macs_2022-2023/macs30200/replication-materials-jiayanli/data'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the current working directory path\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Print the updated directory path\n",
    "data_path = cwd.rstrip(\"/clean\") + \"/data\"\n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "df_raw = pd.read_csv(data_path + \"/raw_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Period</th>\n",
       "      <th>Username</th>\n",
       "      <th>Date</th>\n",
       "      <th>URL</th>\n",
       "      <th>Content</th>\n",
       "      <th>TweetID</th>\n",
       "      <th>MentionedUsers</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>CountryCode</th>\n",
       "      <th>Place</th>\n",
       "      <th>UserID</th>\n",
       "      <th>FollowersCount</th>\n",
       "      <th>UserDescription</th>\n",
       "      <th>UserURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tewillmott</td>\n",
       "      <td>2019-08-14T23:59:42+00:00</td>\n",
       "      <td>https://twitter.com/tewillmott/status/11617895...</td>\n",
       "      <td>Be your own motivation.  Sweat today smile tom...</td>\n",
       "      <td>1161789524902440960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2378977625</td>\n",
       "      <td>239</td>\n",
       "      <td>Make up artist for film and television.  Also ...</td>\n",
       "      <td>https://twitter.com/tewillmott</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tewillmott</td>\n",
       "      <td>2019-08-14T23:50:39+00:00</td>\n",
       "      <td>https://twitter.com/tewillmott/status/11617872...</td>\n",
       "      <td>Time to kill some FAT ðŸ¥µðŸ¥µ.\\n.\\n.\\n.\\n#health #f...</td>\n",
       "      <td>1161787246460096512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2378977625</td>\n",
       "      <td>239</td>\n",
       "      <td>Make up artist for film and television.  Also ...</td>\n",
       "      <td>https://twitter.com/tewillmott</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tewillmott</td>\n",
       "      <td>2019-08-14T23:45:06+00:00</td>\n",
       "      <td>https://twitter.com/tewillmott/status/11617858...</td>\n",
       "      <td>Challenge yourself every day.\\n..\\n.\\n.\\n#heal...</td>\n",
       "      <td>1161785852357308416</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2378977625</td>\n",
       "      <td>239</td>\n",
       "      <td>Make up artist for film and television.  Also ...</td>\n",
       "      <td>https://twitter.com/tewillmott</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tewillmott</td>\n",
       "      <td>2019-08-14T23:40:11+00:00</td>\n",
       "      <td>https://twitter.com/tewillmott/status/11617846...</td>\n",
       "      <td>Excuses donâ€™t burn calories.\\n..\\n.\\n.\\n#healt...</td>\n",
       "      <td>1161784615822155777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2378977625</td>\n",
       "      <td>239</td>\n",
       "      <td>Make up artist for film and television.  Also ...</td>\n",
       "      <td>https://twitter.com/tewillmott</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tewillmott</td>\n",
       "      <td>2019-08-14T23:36:21+00:00</td>\n",
       "      <td>https://twitter.com/tewillmott/status/11617836...</td>\n",
       "      <td>Letâ€™s get the legs right.\\n.\\n.\\n#health #fitn...</td>\n",
       "      <td>1161783648443482112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2378977625</td>\n",
       "      <td>239</td>\n",
       "      <td>Make up artist for film and television.  Also ...</td>\n",
       "      <td>https://twitter.com/tewillmott</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Period    Username                       Date  \\\n",
       "0       0  tewillmott  2019-08-14T23:59:42+00:00   \n",
       "1       0  tewillmott  2019-08-14T23:50:39+00:00   \n",
       "2       0  tewillmott  2019-08-14T23:45:06+00:00   \n",
       "3       0  tewillmott  2019-08-14T23:40:11+00:00   \n",
       "4       0  tewillmott  2019-08-14T23:36:21+00:00   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://twitter.com/tewillmott/status/11617895...   \n",
       "1  https://twitter.com/tewillmott/status/11617872...   \n",
       "2  https://twitter.com/tewillmott/status/11617858...   \n",
       "3  https://twitter.com/tewillmott/status/11617846...   \n",
       "4  https://twitter.com/tewillmott/status/11617836...   \n",
       "\n",
       "                                             Content              TweetID  \\\n",
       "0  Be your own motivation.  Sweat today smile tom...  1161789524902440960   \n",
       "1  Time to kill some FAT ðŸ¥µðŸ¥µ.\\n.\\n.\\n.\\n#health #f...  1161787246460096512   \n",
       "2  Challenge yourself every day.\\n..\\n.\\n.\\n#heal...  1161785852357308416   \n",
       "3  Excuses donâ€™t burn calories.\\n..\\n.\\n.\\n#healt...  1161784615822155777   \n",
       "4  Letâ€™s get the legs right.\\n.\\n.\\n#health #fitn...  1161783648443482112   \n",
       "\n",
       "  MentionedUsers  Longitude  Latitude CountryCode Place      UserID  \\\n",
       "0            NaN        NaN       NaN         NaN   NaN  2378977625   \n",
       "1            NaN        NaN       NaN         NaN   NaN  2378977625   \n",
       "2            NaN        NaN       NaN         NaN   NaN  2378977625   \n",
       "3            NaN        NaN       NaN         NaN   NaN  2378977625   \n",
       "4            NaN        NaN       NaN         NaN   NaN  2378977625   \n",
       "\n",
       "   FollowersCount                                    UserDescription  \\\n",
       "0             239  Make up artist for film and television.  Also ...   \n",
       "1             239  Make up artist for film and television.  Also ...   \n",
       "2             239  Make up artist for film and television.  Also ...   \n",
       "3             239  Make up artist for film and television.  Also ...   \n",
       "4             239  Make up artist for film and television.  Also ...   \n",
       "\n",
       "                          UserURL  \n",
       "0  https://twitter.com/tewillmott  \n",
       "1  https://twitter.com/tewillmott  \n",
       "2  https://twitter.com/tewillmott  \n",
       "3  https://twitter.com/tewillmott  \n",
       "4  https://twitter.com/tewillmott  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the first lines \n",
    "# Period 0: pre-pandemic, 1: early-pandemic, 2: late-pandemic\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Be your own motivation.  Sweat today smile tomorrow \\n.\\n.\\n.\\n#health #fitness #fit #fitmom #fitnessmodel #fitnessaddict #fitspo #workout #bodybuilding #cardio #gym #train #training #photooftheday #health #healthyâ€¦ https://t.co/R6gFBTUXdT'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect an exmaple of tweet content\n",
    "df_raw['Content'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate NLTK's WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define stopwords\n",
    "# nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Define fitspirational stop words\n",
    "fit_stopwords = {'fit', 'fitness', 'gym', 'workout', 'exercise'}\n",
    "\n",
    "# Add fitspirational stopwords\n",
    "stop_words.update(fit_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the preprocessing function\n",
    "def preprocess_tweet(tweet):\n",
    "    # Remove URLs\n",
    "    tweet = re.sub(r'http\\S+', '', tweet)\n",
    "    \n",
    "    # Remove mentions (@), hashtags (#), puctuation, and '\\n'\n",
    "    tweet = re.sub(r'[@#]\\S+|\\n|[^\\w\\s]', '', tweet)\n",
    "    \n",
    "    # Tokenize the tweet\n",
    "    tokens = word_tokenize(tweet.lower())\n",
    "    \n",
    "    # Remove stopwords\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Lemmatize the tokens\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    # Remove punctuation\n",
    "    tokens = [token for token in tokens if token not in string.punctuation]\n",
    "    \n",
    "    # Join the tokens back into a string\n",
    "    tweet = ' '.join(tokens)\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'motivation sweat today smile tomorrow'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw['Content'] = df_raw['Content'].apply(preprocess_tweet)\n",
    "df_raw['Content'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing tweets: (27134, 15)\n",
      "After removing tweets: (19442, 15)\n"
     ]
    }
   ],
   "source": [
    "# Remove exact duplicates based on tweet text\n",
    "print(f\"Before removing tweets: {df_raw.shape}\")\n",
    "df_raw.drop_duplicates(subset=['Content'], inplace=True)\n",
    "df_raw.reset_index(drop=True, inplace=True)\n",
    "print(f\"After removing tweets: {df_raw.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing empty-token tweets: (19442, 15)\n",
      "After removing empty-token tweets: (19441, 15)\n"
     ]
    }
   ],
   "source": [
    "# Remove empty tweets\n",
    "print(f\"Before removing empty-token tweets: {df_raw.shape}\")\n",
    "df_raw = df_raw[df_raw['Content'] != '']\n",
    "print(f\"After removing empty-token tweets: {df_raw.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the pre-processed dataset\n",
    "df_raw.to_csv(data_path + '/clean_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
